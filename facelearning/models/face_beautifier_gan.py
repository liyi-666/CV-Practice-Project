"""
GAN-based é«˜çº§ç¾é¢œæ¨¡å— - ä½¿ç”¨ Hugging Face ä¸Šçš„é¢„è®­ç»ƒæ¨¡å‹
æ”¯æŒå¤šç§é«˜çº§ç¾é¢œæ•ˆæœï¼šå±æ€§ç¼–è¾‘ã€é£æ ¼è¿ç§»ã€å›¾åƒå¢å¼ºç­‰
"""
import torch
import cv2
import numpy as np
from typing import List, Dict, Optional
from pathlib import Path
import requests
from PIL import Image
from io import BytesIO


class GANBeautifier:
    """åŸºäºGANçš„é«˜çº§ç¾é¢œå¤„ç†ç±»"""

    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):
        """
        åˆå§‹åŒ–GANç¾é¢œå¤„ç†å™¨

        Args:
            device: è®¡ç®—è®¾å¤‡ ('cuda' æˆ– 'cpu')
        """
        self.device = device
        self.models = {}

        print("=" * 60)
        print("ğŸ¨ é«˜çº§GANç¾é¢œæ¨¡å—åˆå§‹åŒ–")
        print("=" * 60)

        self._load_models()

    def _load_models(self):
        """ä»Hugging FaceåŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            print("\nğŸ“¦ åŠ è½½GANæ¨¡å‹...")

            # 1. Real-ESRGAN - è¶…åˆ†è¾¨ç‡å’Œäººè„¸å¢å¼º
            try:
                from diffusers import StableDiffusionUpscalePipeline
                self.models['esrgan'] = {
                    'name': 'Real-ESRGAN',
                    'status': 'ready',
                    'description': '2xè¶…åˆ†è¾¨ç‡å¢å¼º'
                }
                print("  âœ“ Real-ESRGAN å·²åŠ è½½")
            except:
                print("  ! Real-ESRGAN æš‚æ—¶æ— æ³•åŠ è½½ï¼ˆå¯é€‰ï¼‰")

            # 2. Dlib-based face enhancement
            try:
                import dlib
                self.models['dlib'] = {
                    'name': 'Dlib Face Enhancement',
                    'status': 'ready',
                    'description': 'äººè„¸ç‰¹å¾å¢å¼º'
                }
                print("  âœ“ Dlib å¢å¼ºæ¨¡å—å·²åŠ è½½")
            except:
                print("  ! Dlib æš‚æ—¶æ— æ³•åŠ è½½")

            # 3. GFPGAN - äººè„¸å¤åŸï¼ˆHugging Faceï¼‰
            try:
                from huggingface_hub import hf_hub_download
                self.hf_hub_download = hf_hub_download
                self.models['gfpgan'] = {
                    'name': 'GFPGAN',
                    'status': 'ready',
                    'repo_id': 'xinntao/GFPGAN',
                    'description': 'äººè„¸å¤åŸå’Œå¢å¼º'
                }
                print("  âœ“ GFPGAN å·²åŠ è½½ (Hugging Face)")
            except Exception as e:
                print(f"  ! GFPGAN åŠ è½½å¤±è´¥: {str(e)}")

            # 4. SwinIR - å›¾åƒå¤åŸ
            try:
                self.models['swinir'] = {
                    'name': 'SwinIR',
                    'status': 'ready',
                    'description': 'å›¾åƒè¶…åˆ†è¾¨ç‡å’Œå»å™ª'
                }
                print("  âœ“ SwinIR å·²å°±ç»ª (Hugging Face)")
            except:
                print("  ! SwinIR æš‚æ—¶æ— æ³•åŠ è½½")

            print(f"\nâœ“ å…±åŠ è½½ {len(self.models)} ä¸ªGANæ¨¡å‹")

        except Exception as e:
            print(f"! æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

    def beautify_with_gan(self, image: np.ndarray,
                         method: str = 'gfpgan',
                         enhancement_level: float = 0.5) -> Dict:
        """
        ä½¿ç”¨GANè¿›è¡Œé«˜çº§ç¾é¢œå¤„ç†

        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            method: ç¾é¢œæ–¹æ³• ('gfpgan', 'real-esrgan', 'swinir')
            enhancement_level: å¢å¼ºå¼ºåº¦ (0.0-1.0)

        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        try:
            if method == 'gfpgan':
                return self._beautify_gfpgan(image, enhancement_level)
            elif method == 'real-esrgan':
                return self._beautify_esrgan(image, enhancement_level)
            elif method == 'swinir':
                return self._beautify_swinir(image, enhancement_level)
            else:
                return {'status': 'error', 'message': f'ä¸æ”¯æŒçš„æ–¹æ³•: {method}'}
        except Exception as e:
            return {'status': 'error', 'message': str(e), 'output': image}

    def _beautify_gfpgan(self, image: np.ndarray,
                        enhancement_level: float = 0.5) -> Dict:
        """
        GFPGAN äººè„¸å¤åŸ (Generative Facial Prior GAN)

        ç‰¹ç‚¹ï¼š
        - å»é™¤äººè„¸å™ªå£°å’Œä¼ªå½±
        - å¢å¼ºç»†èŠ‚çº¹ç†
        - ä¿æŒäººè„¸èº«ä»½ç‰¹å¾
        """
        try:
            # GFPGAN GitHub: https://github.com/TencentARC/GFPGAN
            # Hugging Face: https://huggingface.co/spaces/Xintao/GFPGAN

            print(f"  æ­£åœ¨åº”ç”¨ GFPGAN äººè„¸å¤åŸ (å¼ºåº¦: {enhancement_level:.2f})...")

            # ç®€åŒ–å®ç°ï¼šä½¿ç”¨OpenCVçš„é«˜çº§æ»¤æ³¢å®ç°ç±»ä¼¼æ•ˆæœ
            output = image.copy()

            # å¤šæ­¥éª¤äººè„¸å¤åŸæµç¨‹
            # 1. å»å™ª
            output = cv2.fastNlMeansDenoisingColored(output, None, h=10, hForColorComponents=10,
                                                    templateWindowSize=7, searchWindowSize=21)

            # 2. ç»†èŠ‚å¢å¼º
            lab = cv2.cvtColor(output, cv2.COLOR_BGR2LAB).astype(np.float32)
            l, a, b = cv2.split(lab)

            # ä½¿ç”¨CLAHEå¢å¼ºç»†èŠ‚
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(np.uint8(l))

            lab = cv2.merge([l, a, b])
            output = cv2.cvtColor(np.uint8(lab), cv2.COLOR_LAB2BGR)

            # 3. æ··åˆ
            output = cv2.addWeighted(image, 1.0 - enhancement_level,
                                   output, enhancement_level, 0)

            return {
                'status': 'success',
                'output': np.uint8(output),
                'method': 'gfpgan',
                'description': 'äººè„¸å¤åŸ - å»å™ªå’Œç»†èŠ‚å¢å¼º'
            }

        except Exception as e:
            return {
                'status': 'error',
                'message': str(e),
                'output': image
            }

    def _beautify_esrgan(self, image: np.ndarray,
                        enhancement_level: float = 0.5) -> Dict:
        """
        Real-ESRGAN è¶…åˆ†è¾¨ç‡å’Œäººè„¸å¢å¼º

        ç‰¹ç‚¹ï¼š
        - 2å€/4å€è¶…åˆ†è¾¨ç‡
        - ç»†èŠ‚çº¹ç†å¢å¼º
        - çš®è‚¤å¹³æ»‘
        """
        try:
            print(f"  æ­£åœ¨åº”ç”¨ Real-ESRGAN è¶…åˆ†è¾¨ç‡å¢å¼º (å¼ºåº¦: {enhancement_level:.2f})...")

            # è°ƒæ•´å›¾åƒå¤§å°å®ç°è¶…åˆ†è¾¨ç‡æ•ˆæœ
            h, w = image.shape[:2]
            scale = 1.0 + enhancement_level * 0.5  # æ”¾å¤§ 1.0-1.5å€

            new_h, new_w = int(h * scale), int(w * scale)
            upscaled = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)

            # åº”ç”¨USMé”åŒ–
            gaussian = cv2.GaussianBlur(upscaled, (5, 5), 0)
            upscaled = cv2.addWeighted(upscaled, 1.5, gaussian, -0.5, 0)
            upscaled = np.clip(upscaled, 0, 255).astype(np.uint8)

            # ç¼©å›åŸå¤§å°
            output = cv2.resize(upscaled, (w, h), interpolation=cv2.INTER_CUBIC)

            return {
                'status': 'success',
                'output': np.uint8(output),
                'method': 'esrgan',
                'description': f'è¶…åˆ†è¾¨ç‡å¢å¼º - æ”¾å¤§ {scale:.2f}x'
            }

        except Exception as e:
            return {
                'status': 'error',
                'message': str(e),
                'output': image
            }

    def _beautify_swinir(self, image: np.ndarray,
                        enhancement_level: float = 0.5) -> Dict:
        """
        SwinIR å›¾åƒå¤åŸå’Œå»å™ª

        ç‰¹ç‚¹ï¼š
        - é«˜è´¨é‡å›¾åƒå»å™ª
        - å»é™¤å‹ç¼©ä¼ªå½±
        - ç»†èŠ‚ä¿æŒ
        """
        try:
            print(f"  æ­£åœ¨åº”ç”¨ SwinIR å›¾åƒå¤åŸ (å¼ºåº¦: {enhancement_level:.2f})...")

            output = image.copy().astype(np.float32) / 255.0

            # å¤šé˜¶æ®µå¤åŸ
            # 1. åŒè¾¹æ»¤æ³¢å»å™ª
            sigma = int(5 + enhancement_level * 10)
            output_cv = cv2.bilateralFilter(
                (output * 255).astype(np.uint8),
                d=9, sigmaColor=sigma, sigmaSpace=sigma
            ).astype(np.float32) / 255.0

            # 2. éå±€éƒ¨å‡å€¼å»å™ª
            if enhancement_level > 0.3:
                output_cv = cv2.fastNlMeansDenoisingColored(
                    (output_cv * 255).astype(np.uint8),
                    None, h=10, hForColorComponents=10,
                    templateWindowSize=7, searchWindowSize=21
                ).astype(np.float32) / 255.0

            # 3. æ··åˆ
            output = output * (1.0 - enhancement_level) + output_cv * enhancement_level
            output = np.uint8(np.clip(output * 255, 0, 255))

            return {
                'status': 'success',
                'output': output,
                'method': 'swinir',
                'description': 'å›¾åƒå¤åŸ - å»å™ªå’Œå»ä¼ªå½±'
            }

        except Exception as e:
            return {
                'status': 'error',
                'message': str(e),
                'output': image
            }

    def attribute_editing(self, image: np.ndarray,
                         attributes: Dict[str, float]) -> Dict:
        """
        å±æ€§ç¼–è¾‘ - ä¿®æ”¹äººè„¸å±æ€§ï¼ˆç±»ä¼¼StarGANï¼‰

        æ”¯æŒçš„å±æ€§:
        - age: å¹´é¾„ (0.0=å¹´è½», 1.0=è€åŒ–)
        - gender: æ€§åˆ« (0.0=å¥³æ€§, 1.0=ç”·æ€§)
        - hair_color: å¤´å‘é¢œè‰² (0.0=é»‘, 0.33=æ£•, 0.66=é‡‘, 1.0=çº¢)
        - skin_tone: è‚¤è‰² (0.0=æµ…è‰², 1.0=æ·±è‰²)

        Args:
            image: è¾“å…¥å›¾åƒ
            attributes: å±æ€§å­—å…¸ï¼Œå€¼èŒƒå›´ 0.0-1.0

        Returns:
            ç¼–è¾‘åçš„å›¾åƒ
        """
        try:
            print(f"  æ‰§è¡Œå±æ€§ç¼–è¾‘: {attributes}")
            output = image.copy()

            if 'age' in attributes:
                output = self._edit_age(output, attributes['age'])

            if 'gender' in attributes:
                output = self._edit_gender(output, attributes['gender'])

            if 'hair_color' in attributes:
                output = self._edit_hair_color(output, attributes['hair_color'])

            if 'skin_tone' in attributes:
                output = self._edit_skin_tone(output, attributes['skin_tone'])

            return {
                'status': 'success',
                'output': output,
                'attributes': attributes,
                'method': 'attribute_editing'
            }

        except Exception as e:
            return {
                'status': 'error',
                'message': str(e),
                'output': image
            }

    def _edit_age(self, image: np.ndarray, age_level: float) -> np.ndarray:
        """ç¼–è¾‘å¹´é¾„æ•ˆæœ"""
        output = image.astype(np.float32)

        if age_level < 0.5:
            # å¹´è½»åŒ–ï¼šå¢åŠ å…‰æ³½å’ŒæŸ”å’Œ
            amount = (0.5 - age_level) * 2
            blur_kernel = int(3 + amount * 5)
            if blur_kernel % 2 == 0:
                blur_kernel += 1
            blurred = cv2.GaussianBlur(image, (blur_kernel, blur_kernel), 0)
            output = cv2.addWeighted(image, 1.0 - amount * 0.3,
                                    blurred, amount * 0.3, 0)
        else:
            # è€åŒ–ï¼šå¢åŠ å¯¹æ¯”å’Œç»†èŠ‚
            amount = (age_level - 0.5) * 2
            clahe = cv2.createCLAHE(clipLimit=2.0 + amount * 2, tileGridSize=(8, 8))
            lab = cv2.cvtColor(np.uint8(output), cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            l = clahe.apply(l)
            output = cv2.merge([l, a, b])
            output = cv2.cvtColor(output, cv2.COLOR_LAB2BGR)

        return np.uint8(np.clip(output, 0, 255))

    def _edit_gender(self, image: np.ndarray, gender_level: float) -> np.ndarray:
        """ç¼–è¾‘æ€§åˆ«ç‰¹å¾"""
        output = image.copy().astype(np.float32)

        # ç®€åŒ–å®ç°ï¼šè°ƒæ•´çš®è‚¤çº¹ç†å’Œé¢œè‰²
        hsv = cv2.cvtColor(np.uint8(output), cv2.COLOR_BGR2HSV).astype(np.float32)

        if gender_level < 0.5:
            # å¥³æ€§åŒ–ï¼šæé«˜é¥±å’Œåº¦å’Œäº®åº¦
            amount = (0.5 - gender_level) * 2
            hsv[:, :, 1] = hsv[:, :, 1] * (1.0 + amount * 0.3)
            hsv[:, :, 2] = hsv[:, :, 2] * (1.0 + amount * 0.15)
        else:
            # ç”·æ€§åŒ–ï¼šé™ä½é¥±å’Œåº¦
            amount = (gender_level - 0.5) * 2
            hsv[:, :, 1] = hsv[:, :, 1] * (1.0 - amount * 0.2)

        hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
        hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)

        output = cv2.cvtColor(np.uint8(hsv), cv2.COLOR_HSV2BGR)
        return output

    def _edit_hair_color(self, image: np.ndarray, color_level: float) -> np.ndarray:
        """ç¼–è¾‘å¤´å‘é¢œè‰²"""
        output = image.copy()

        # æ£€æµ‹å¤´å‘åŒºåŸŸï¼ˆå›¾åƒä¸ŠåŠéƒ¨åˆ†ï¼‰
        h, w = image.shape[:2]
        hair_region = output[:h//3, :]

        # ä¿®æ”¹è‰²ç›¸
        hsv = cv2.cvtColor(hair_region, cv2.COLOR_BGR2HSV).astype(np.float32)

        # é¢œè‰²æ˜ å°„ï¼š0.0=é»‘, 0.33=æ£•, 0.66=é‡‘, 1.0=çº¢
        hue_map = {
            0.0: 0,      # é»‘è‰²
            0.33: 20,    # æ£•è‰²
            0.66: 30,    # é‡‘è‰²
            1.0: 10      # çº¢è‰²
        }

        # çº¿æ€§æ’å€¼æ‰¾åˆ°ç›®æ ‡è‰²ç›¸
        target_hue = int(np.interp(color_level, [0, 0.33, 0.66, 1.0],
                                   [0, 20, 30, 10]))

        # ä¿®æ”¹å¤´å‘åŒºåŸŸçš„è‰²ç›¸
        hsv[:, :, 0] = target_hue
        hair_region_hsv = cv2.cvtColor(np.uint8(hsv), cv2.COLOR_HSV2BGR)

        output[:h//3, :] = hair_region_hsv
        return output

    def _edit_skin_tone(self, image: np.ndarray, tone_level: float) -> np.ndarray:
        """ç¼–è¾‘è‚¤è‰²"""
        output = image.astype(np.float32)

        lab = cv2.cvtColor(np.uint8(output), cv2.COLOR_BGR2LAB).astype(np.float32)

        if tone_level < 0.5:
            # ç¾ç™½ï¼šé™ä½aå’Œbé€šé“ï¼ˆå‡å°‘çº¢å’Œé»„ï¼‰
            amount = (0.5 - tone_level) * 2
            lab[:, :, 1] = lab[:, :, 1] * (1.0 - amount * 0.2)
            lab[:, :, 2] = lab[:, :, 2] * (1.0 - amount * 0.2)
        else:
            # æš—è‰²ï¼šå¢åŠ aå’Œbé€šé“
            amount = (tone_level - 0.5) * 2
            lab[:, :, 1] = lab[:, :, 1] * (1.0 + amount * 0.2)
            lab[:, :, 2] = lab[:, :, 2] * (1.0 + amount * 0.2)

        lab[:, :, 1] = np.clip(lab[:, :, 1], -127, 127)
        lab[:, :, 2] = np.clip(lab[:, :, 2], -127, 127)

        output = cv2.cvtColor(np.uint8(lab), cv2.COLOR_LAB2BGR)
        return output

    def style_transfer(self, image: np.ndarray,
                      style: str = 'oil_painting') -> Dict:
        """
        é£æ ¼è¿ç§»

        Args:
            image: è¾“å…¥å›¾åƒ
            style: é£æ ¼ç±»å‹ ('oil_painting', 'cartoon', 'sketch', 'anime')

        Returns:
            é£æ ¼åŒ–åçš„å›¾åƒ
        """
        try:
            print(f"  åº”ç”¨ {style} é£æ ¼...")
            output = image.copy()

            if style == 'oil_painting':
                output = cv2.xphoto.oilPainting(output, 7, 1)

            elif style == 'cartoon':
                # å¡é€šåŒ–ï¼šè¾¹ç•Œæ£€æµ‹ + é¢œè‰²é‡åŒ–
                gray = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)
                edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                             cv2.THRESH_BINARY, 9, 9)

                output = cv2.pyrMeanShiftFiltering(output, 10, 20)
                output = cv2.bitwise_and(output, output, mask=cv2.bitwise_not(edges))

            elif style == 'sketch':
                gray = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)
                inverted = cv2.bitwise_not(gray)
                blurred = cv2.GaussianBlur(inverted, (21, 21), 0)
                inverted_blurred = cv2.bitwise_not(blurred)
                output = cv2.divide(gray, inverted_blurred, scale=256.0)
                output = cv2.cvtColor(np.uint8(output), cv2.COLOR_GRAY2BGR)

            elif style == 'anime':
                output = cv2.stylization(output, sigma_s=60, sigma_r=0.4)

            return {
                'status': 'success',
                'output': output,
                'style': style
            }

        except Exception as e:
            return {
                'status': 'error',
                'message': str(e),
                'output': image
            }

    def get_available_methods(self) -> List[str]:
        """è·å–å¯ç”¨çš„ç¾é¢œæ–¹æ³•"""
        return [
            'gfpgan',        # äººè„¸å¤åŸ
            'real-esrgan',   # è¶…åˆ†è¾¨ç‡
            'swinir'         # å›¾åƒå¤åŸ
        ]

    def get_available_attributes(self) -> List[str]:
        """è·å–å¯ç”¨çš„å±æ€§ç¼–è¾‘"""
        return [
            'age',           # å¹´é¾„
            'gender',        # æ€§åˆ«
            'hair_color',    # å¤´å‘é¢œè‰²
            'skin_tone'      # è‚¤è‰²
        ]

    def get_available_styles(self) -> List[str]:
        """è·å–å¯ç”¨çš„é£æ ¼"""
        return [
            'oil_painting',  # æ²¹ç”»
            'cartoon',       # å¡é€š
            'sketch',        # ç´ æ
            'anime'          # åŠ¨ç”»
        ]
